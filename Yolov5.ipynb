{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3hO6S2RjfLkY"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DEp-bp2_z8Tn"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class res_block(nn.Module):\n","  def __init__(self, in_channels=32, out_channels=32, stride=1, downsample=None, expansions=1):\n","    super(res_block, self).__init__()\n","    in_channels = in_channels\n","    out_channels = out_channels\n","    self.conv1 = nn.Sequential(\n","                    nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, ),\n","                    nn.BatchNorm2d(out_channels),\n","                    nn.SiLU())\n","    self.conv2 = nn.Sequential(\n","                    nn.Conv2d(out_channels, in_channels, kernel_size=3, stride=1, padding=1),\n","                    nn.BatchNorm2d(in_channels),\n","                    nn.SiLU())\n","  def forward(self, x):\n","      residual = x\n","      out = self.conv1(x)\n","\n","      out = self.conv2(out)\n","\n","      out += residual\n","\n","\n","      return out\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MpB9OTFuortb"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class BottleNeck2(nn.Module):\n","  def __init__(self, channels=0):\n","    super(BottleNeck2, self).__init__()\n","    in_channels = channels\n","    out_channels = channels\n","    self.conv1 = nn.Sequential(\n","                    nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, ),\n","                    nn.BatchNorm2d(out_channels),\n","                    nn.SiLU())\n","    self.conv2 = nn.Sequential(\n","                    nn.Conv2d(out_channels, in_channels, kernel_size=3, stride=1, padding=1),\n","                    nn.BatchNorm2d(in_channels),\n","                    nn.SiLU())\n","  def forward(self, x):\n","\n","      out = self.conv1(x)\n","\n","      out = self.conv2(out)\n","\n","\n","\n","      return out\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LLDRYdNFopOL"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FUl6lgN_FItU"},"outputs":[],"source":["from torch.nn.modules.activation import LeakyReLU\n","class cspdarknet(nn.Module):\n","  def __init__(self, ):\n","    super(cspdarknet, self).__init__()\n","    block = res_block\n","    self.conv0 = nn.Sequential(\n","                    nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n","                    nn.BatchNorm2d(64),\n","                    nn.SiLU(),)\n","    self.downsample1 = nn.Sequential(\n","        nn.Conv2d(64 ,128, kernel_size=3, stride=2, padding=1,),\n","        nn.BatchNorm2d(128),\n","        nn.SiLU()\n","\n","    )\n","    self.conv1 = nn.Sequential(\n","        nn.Conv2d(128, 64, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(64),\n","        nn.SiLU()\n","    )\n","    self.conv2 = nn.Sequential(\n","        nn.Conv2d(128, 64, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(64),\n","        nn.SiLU()\n","    )\n","\n","    self.block1 = self._make_block(block, in_cha=64, out_cha=64, repeats = 3, expansion=2)\n","\n","    self.convb1 = nn.Sequential(\n","        nn.Conv2d(128, 128, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(128),\n","        nn.SiLU()\n","    )\n","    self.downsample2 = nn.Sequential(\n","        nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.SiLU()\n","    )\n","    self.conv3 = nn.Sequential(\n","        nn.Conv2d(256, 128, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(128),\n","        nn.SiLU()\n","    )\n","    self.conv4 = nn.Sequential(\n","        nn.Conv2d(256, 128, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(128),\n","        nn.SiLU()\n","    )\n","    self.block2 = self._make_block(block, in_cha=128, out_cha=128,repeats=6, expansion=4)\n","\n","    self.convb2 = nn.Sequential(\n","        nn.Conv2d(256, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.SiLU()\n","    )\n","    self.downsample3 = nn.Sequential(\n","        nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.SiLU()\n","    )\n","    self.conv5 = nn.Sequential(\n","        nn.Conv2d(512, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.SiLU()\n","    )\n","    self.conv6 = nn.Sequential(\n","        nn.Conv2d(512, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.SiLU()\n","    )\n","    self.block3 = self._make_block(block, in_cha=256, out_cha=256, repeats=9, expansion=8)\n","\n","    self.convb3 = nn.Sequential(\n","        nn.Conv2d(512, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.SiLU()\n","    )\n","    self.downsample4 = nn.Sequential(\n","        nn.Conv2d(512, 1024, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(1024),\n","        nn.SiLU()\n","    )\n","\n","    self.conv7 = nn.Sequential(\n","        nn.Conv2d(1024, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.SiLU()\n","    )\n","    self.conv8 = nn.Sequential(\n","        nn.Conv2d(1024, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.SiLU()\n","    )\n","    self.block4 = self._make_block(block, in_cha=512, out_cha=512, repeats=3, expansion=16)\n","\n","    self.convb4 = nn.Sequential(\n","        nn.Conv2d(1024, 1024, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(1024),\n","        nn.SiLU()\n","    )\n","  def _make_block(self, block, in_cha=64, out_cha=64, repeats=0, expansion=0):\n","    layers = []\n","\n","    for i in range(repeats):\n","      layers.append(block(in_channels=in_cha, out_channels=out_cha ,expansions=expansion))\n","\n","    return nn.Sequential(*layers)\n","\n","  def forward(self, x):\n","    x = self.conv0(x)\n","    down_s1 = self.downsample1(x)\n","\n","    ## block1\n","\n","    x0 = self.conv1(down_s1)\n","    x1 = self.conv2(down_s1)\n","\n","    b1 = self.block1(x1)\n","    b1 = torch.cat((b1,x0), dim=1)\n","    b1 = self.convb1(b1)\n","    down_s2 = self.downsample2(b1)\n","    ##block2\n","\n","    x0 = self.conv3(down_s2)\n","    x1 = self.conv4(down_s2)\n","\n","    b2 = self.block2(x1)\n","    b2 = torch.cat((b2, x0), dim=1)\n","    b2 = self.convb2(b2)\n","    down_s3 = self.downsample3(b2)\n","    ## block3\n","\n","    x0 = self.conv5(down_s3)\n","    x1 = self.conv6(down_s3)\n","\n","\n","    b3 = self.block3(x1)\n","    b3 = torch.cat((b3, x0), dim=1)\n","    b3 = self.convb3(b3)\n","    down_s4 = self.downsample4(b3)\n","    ## block4\n","\n","    x0 = self.conv7(down_s4)\n","    x1 = self.conv8(down_s4)\n","\n","    b4 = self.block4(x1)\n","\n","\n","    b4 = torch.cat((b4,x0), dim=1)\n","    b4 = self.convb4(b4)\n","\n","\n","\n","    return {'b4':b4, 'b3':b3, 'b2':b2}\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZQ5ZYsCtfeQV"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TXThmykXz7-K"},"outputs":[],"source":["import torch.nn.functional as F\n","class Yolov5(nn.Module):\n","  def __init__(self, ):\n","    super(Yolov5, self).__init__()\n","    self.cspdarknet = cspdarknet()\n","    block = BottleNeck2\n","    self.spp_conv1 = nn.Sequential(\n","        nn.Conv2d(1024, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.SiLU()\n","    )\n","    #self.conv_spp2 = self._make_into_spp_convs()\n","    self.spp1 = self._make_spp(5)\n","    self.spp2 = self._make_spp(5)\n","    self.spp3 = self._make_spp(5)\n","    self.spp_conv2 = nn.Sequential(\n","        nn.Conv2d(2048, 1024, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(1024),\n","        nn.SiLU(),\n","        nn.Conv2d(1024, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.SiLU()\n","    )\n","    self.conv1 = nn.Sequential(\n","        nn.Conv2d(1024, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.SiLU()\n","    )\n","    self.conv2 = nn.Sequential(\n","        nn.Conv2d(1024, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.SiLU()\n","    )\n","    self.block1 = self._make_bottleneck(block ,channels=512, repeats=3)\n","    self.conv3 = nn.Sequential(\n","        nn.Conv2d(1024, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.SiLU()\n","    )\n","    self.conv4 = nn.Sequential(\n","        nn.Conv2d(512, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.SiLU()\n","    )\n","    self.conv5 = nn.Sequential(\n","        nn.Conv2d(512, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.SiLU()\n","    )\n","    self.conv6 = nn.Sequential(\n","        nn.Conv2d(512, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.SiLU()\n","    )\n","    self.block2 = self._make_bottleneck(block, channels=256, repeats=3)\n","    self.conv7 = nn.Sequential(\n","        nn.Conv2d(512, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.SiLU()\n","    )\n","    self.downsample_one = nn.Sequential(\n","        nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.SiLU()\n","    )\n","\n","    self.conv8 = nn.Sequential(\n","        nn.Conv2d(512, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.SiLU()\n","    )\n","    self.conv9 = nn.Sequential(\n","        nn.Conv2d(512, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.SiLU()\n","    )\n","    self.block3 = self._make_bottleneck(block, channels=256, repeats=3)\n","    self.conv10 = nn.Sequential(\n","        nn.Conv2d(512, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.SiLU()\n","    )\n","    self.downsample_two = nn.Sequential(\n","        nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.SiLU()\n","    )\n","\n","\n","    self.conv11 = nn.Sequential(\n","        nn.Conv2d(1024, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.SiLU()\n","    )\n","\n","    self.conv12 = nn.Sequential(\n","        nn.Conv2d(1024, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.SiLU()\n","    )\n","    self.block4 = self._make_bottleneck(block, channels=512, repeats=3)\n","\n","\n","    self.conv13 = nn.Sequential(\n","        nn.Conv2d(1024, 1024, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(1024),\n","        nn.SiLU()\n","    )\n","\n","    self.output1 = self._final_layer( 1024)\n","    self.output2 = self._final_layer( 512)\n","    self.output3 = self._final_layer( 256)\n","\n","  def _make_bottleneck(self, block, channels=0, repeats=0):\n","    layers = []\n","    for i in range(repeats):\n","      layers.append(block(channels))\n","    return nn.Sequential(*layers)\n","\n","  def _final_layer(self, input):\n","\n","     return  nn.Conv2d(input, 15, kernel_size=1, stride=1)\n","\n","\n","\n","  def _make_spp(self, size):\n","    return nn.MaxPool2d(kernel_size=size, stride=1, padding=size//2)\n","\n","\n","\n","  def forward(self, images, targets, anchors):\n","      ## feature extraction\n","      features = self.cspdarknet(images)\n","\n","      ## spp start\n","      #x0 = self.conv_spp1(x['b4'])\n","      x = self.spp_conv1(features['b4'])\n","      spp1 = self.spp1(x)\n","      spp2 = self.spp2(spp1)\n","      spp3 = self.spp3(spp2)\n","      b4 = torch.cat((spp1, spp2, spp3, x), dim=1)\n","      b4 = self.spp_conv2(b4)\n","\n","      #b4 = torch.cat((b4, x0), dim=1)\n","      #b4 = self.conv1(b4)\n","      ## ssp finish\n","\n","      ## pan start\n","      #b4_route = self.conv2(b4)\n","      upsampled_one = F.interpolate(b4, (26, 26), mode='nearest')\n","      b3 = features['b3']\n","      concat_one = torch.cat((b3, upsampled_one), dim=1)\n","\n","      b3 = self.conv1(concat_one)\n","      b3_route = self.conv2(concat_one)\n","      b3_route = self.block1(b3_route)\n","      b3 = torch.cat((b3, b3_route ),dim=1)\n","      b3 = self.conv3(b3)\n","      b3 = self.conv4(b3)\n","\n","\n","      upsampled_two = F.interpolate(b3, (52,52), mode='nearest')\n","      b2 = features['b2']\n","      concat_two = torch.cat((upsampled_two,b2), dim=1)\n","\n","      b2 = self.conv5(concat_two)\n","      b2_route = self.conv6(concat_two)\n","      b2_route = self.block2(b2_route)\n","      b2 = torch.cat((b2, b2_route), dim=1)\n","      b2 = self.conv7(b2)\n","\n","\n","      downsample_one = self.downsample_one(b2)\n","      concat_pan_one = torch.cat((downsample_one, b3), dim=1)\n","\n","      b3 = self.conv8(concat_pan_one)\n","      b3_route = self.conv9(concat_pan_one)\n","      b3_route = self.block3(b3_route)\n","      b3 = torch.cat((b3, b3_route), dim=1)\n","      b3 = self.conv10(b3)\n","\n","\n","      downsample_two = self.downsample_two(b3)\n","      concat_pan_two = torch.cat((downsample_two, b4), dim=1)\n","\n","      b4 = self.conv11(concat_pan_two)\n","      b4_route = self.conv12(concat_pan_two)\n","      b4_route = self.block4(b4_route)\n","      b4 = torch.cat((b4, b4_route), dim=1)\n","      b4 = self.conv13(b4)\n","\n","\n","      ## pan finished\n","\n","      output_s = self.output3(b2).permute(0,2,3,1).view(-1,52,52,3,5)\n","      output_m = self.output2(b3).permute(0,2,3,1).view(-1,26,26,3,5)\n","      output_b = self.output1(b4).permute(0,2,3,1).view(-1,13,13,3,5)\n","\n","      loss_outputs = output_preprocessing(output_s, output_m, output_b, targets, images, anchors)\n","\n","      return (loss_outputs['offset_loss'] *0.05+ loss_outputs['obj_loss']+\n","              loss_outputs['noobj_loss']*0.632), loss_outputs\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ei9cjOHRY0Ij"},"outputs":[],"source":["from tqdm import tqdm\n","from functools import partial\n","tqdm = partial(tqdm, position=0, leave=True)\n","import torch\n","import numpy as np\n","import time\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","\n","def train_epocs(model, optimizer, data_loader, devie, all_anchors ,epochs=30,training_state=False ):\n","\n","    for epoch in range(epochs):\n","        if epoch==30:\n","           parameters = model.parameters()\n","           optimizer = torch.optim.SGD(parameters, lr = 0.000002,\n","                                       momentum=0.99)\n","        total = 0\n","        sum_loss = 0\n","        sum_loss_classifier = 0\n","        sum_loss_offsets = 0\n","        sum_loss_noobj = 0\n","        sum_loss_obj = 0\n","\n","        iteration_num = 0\n","\n","        for i, data in enumerate(tqdm(data_loader)):\n","            images = data[0].to(device)\n","            targets = data[1]\n","            batch_length = len(images)\n","            ### gradient tracking\n","            if not training_state:\n","               with torch.no_grad():\n","                  model.eval()\n","                  output = model(images, targets = targets, anchors = all_anchors)\n","            else:\n","                 model.train()\n","                 output = model(images, targets, all_anchors)\n","            Final_loss = output[0]\n","            Final_loss.backward()\n","            if training_state and i%12==0:\n","               optimizer.step()\n","               optimizer.zero_grad()\n","\n","\n","            iteration_num += 1\n","            total += batch_length\n","\n","            sum_loss += output[0]\n","            #sum_loss_classifier += output[1]\n","            sum_loss_offsets += output[1]['offset_loss']\n","            sum_loss_noobj += output[1]['noobj_loss']\n","            sum_loss_obj += output[1]['obj_loss']\n","\n","            if iteration_num % 50 == 0:\n","\n","                train_loss = sum_loss/total\n","                train_loss_classifier = sum_loss_classifier/total\n","                train_loss_offsets = sum_loss_offsets/total\n","                train_loss_noobj = sum_loss_noobj/total\n","                train_loss_obj = sum_loss_obj/total\n","                print(\"loss %.6f classifer %.6f regressor %.6f noobj_loss %.6f obj_loss %.6f \"%\n","                      (train_loss, train_loss_classifier, train_loss_offsets, train_loss_noobj, train_loss_obj))\n","                total = 0.0\n","                sum_loss= 0.0\n","                sum_loss_classifier = 0.0\n","                sum_loss_offsets = 0.0\n","                sum_loss_noobj = 0.0\n","                sum_loss_obj = 0.0\n","\n","\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2164,"status":"ok","timestamp":1693255667738,"user":{"displayName":"HAITHAM AL-TOSAIMI","userId":"14079608149427840165"},"user_tz":-120},"id":"QH1IuCwB7SQ9","outputId":"f85f117c-910f-44a3-b2bf-6fb2030e7e7f"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","model = Yolov5().to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-2 , momentum = 0.937, weight_decay=0.0005)\n","print(device)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VdjGvLXHfKiL"},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"tF153O-u6_6p"},"outputs":[],"source":["train = train_epocs(model, optimizer, data_loader, device, all_anchors, epochs=20 ,training_state=True)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5xQYF-mopUcr"},"outputs":[],"source":["\n","def output_preprocessing(prediction_s, prediction_m,\n","                         prediction_b, gt_boxes, images, anchors):\n","\n","  noobj_batch_loss = 0\n","  obj_batch_loss = 0\n","  offsets_batch_loss = 0\n","  for pred_s, pred_m, pred_b, gt in zip(prediction_s, prediction_m, prediction_b, gt_boxes):\n","      pred_offsets_s, pred_offsets_m, pred_offsets_b = [], [], []\n","      target_offsets_s, target_offsets_m, target_offsets_b = [], [], []\n","      used_cell = []\n","      used_anchor_cell = []\n","      centroids = [ sample[1] for sample in gt ]\n","      boxes_in_image = torch.stack([ sample[2] for sample in gt])\n","\n","\n","      pred_s_to_loss = torch.zeros_like(pred_s, )\n","      pred_s_to_loss[:,:,:,4]=1\n","      pred_m_to_loss = torch.zeros_like(pred_m, )\n","      pred_m_to_loss[:,:,:,4]=1\n","      pred_b_to_loss = torch.zeros_like(pred_b,)\n","      pred_b_to_loss[:,:,:,4]=1\n","      #img = images[0].to(torch.device('cuda')).numpy().transpose(1,2,0).copy()\n","\n","      for idx, grid_cells in enumerate(centroids):\n","\n","          small_cell   = grid_cells[0]\n","          medium_cell  = grid_cells[1]\n","          big_cell     = grid_cells[2]\n","\n","          current_box  = boxes_in_image[idx].unsqueeze(0)\n","\n","          small_cell_anchors  = torch.tensor(anchors['small'][ small_cell[0]*52 + small_cell[1]])\n","          medium_cell_anchors = torch.tensor(anchors['medium'][ medium_cell[0]*26 + medium_cell[1]])\n","          big_cell_anchors    = torch.tensor(anchors['big'][ big_cell[0]*13 + big_cell[1]])\n","\n","          anchors_in_cell     = torch.cat((small_cell_anchors,\n","                                         medium_cell_anchors,\n","                                         big_cell_anchors))\n","\n","          pos_anchor, anchor_cell_location, cell_location, ignore_anchors = anchors_assignment(current_box,\n","                                                                         anchors_in_cell,\n","                                                                         grid_cells,\n","                                                                         used_anchor_cell,\n","                                                                         used_cell, idx)\n","\n","\n","          if pos_anchor is not None and pos_anchor < 3:\n","            pred_s_to_loss[grid_cells[0][0], grid_cells[0][1], pos_anchor, 4] = 0\n","            pred_offset = pred_s[grid_cells[0][0], grid_cells[0][1], pos_anchor]\n","            size = 's'\n","          elif pos_anchor is not None and pos_anchor >= 3 and pos_anchor < 6:\n","            pred_m_to_loss[grid_cells[1][0], grid_cells[1][1], pos_anchor - 3, 4 ] = 0\n","            pred_offset = pred_m[grid_cells[1][0], grid_cells[1][1], pos_anchor - 3]\n","            size = 'm'\n","          elif pos_anchor is not None and pos_anchor>=6 and pos_anchor<9:\n","            pred_b_to_loss[grid_cells[2][0], grid_cells[2][1], pos_anchor - 6, 4] = 0\n","            pred_offset = pred_b[grid_cells[2][0], grid_cells[2][1], pos_anchor - 6]\n","            size = 'b'\n","\n","          for ignore_idx in ignore_anchors:\n","            if ignore_idx < 3:\n","              if pred_s_to_loss[grid_cells[0][0], grid_cells[0][1], ignore_idx, 4] == 1:\n","                pred_s_to_loss[grid_cells[0][0], grid_cells[0][1], ignore_idx, 4] = -1\n","            elif ignore_idx >= 3 and ignore_idx<6:\n","              if pred_m_to_loss[grid_cells[1][0], grid_cells[1][1], ignore_idx - 3, 4] == 1:\n","                pred_m_to_loss[grid_cells[1][0], grid_cells[1][1], ignore_idx - 3, 4] = -1\n","            elif ignore_idx >=6:\n","              if pred_b_to_loss[grid_cells[2][0], grid_cells[2][1], ignore_idx - 6, 4] == 1:\n","                pred_b_to_loss[grid_cells[2][0], grid_cells[2][1], ignore_idx - 6, 4] = -1\n","\n","\n","          used_cell.append(cell_location)\n","          used_anchor_cell.append(anchor_cell_location)\n","          if pos_anchor is not None:\n","            scale = 8 if anchor_cell_location[1]<3 else 16 if anchor_cell_location[1]<6 else 32\n","            assigned_anchor = anchors_in_cell[pos_anchor].unsqueeze(0)\n","            if size=='s':\n","               pred_offsets_s.append(pred_offset)\n","               target_offset = target_calculation(assigned_anchor, current_box, scale)\n","               target_offsets_s.append(target_offset)\n","\n","            elif size=='m':\n","               pred_offsets_m.append(pred_offset)\n","               target_offset = target_calculation(assigned_anchor, current_box, scale)\n","               target_offsets_m.append(target_offset)\n","\n","            elif size=='b':\n","               pred_offsets_b.append(pred_offset)\n","               target_offset = target_calculation(assigned_anchor, current_box, scale)\n","               target_offsets_b.append(target_offset)\n","\n","            '''\n","            for d, b in zip(assigned_anchor, current_box):\n","              x1 = int(d[0])\n","              y1 = int(d[1])\n","              x2 = int(d[2])\n","              y2 = int(d[3])\n","              xx = int(b[0] - b[2]/2)\n","              yy = int(b[1] - b[3]/2)\n","              xx1 = int(b[2]/2 + b[0])\n","              yy1 = int(b[3]/2 + b[1])\n","              cv2.rectangle(img, (x1, y1), (x2, y2), (0,0,255), 2)\n","              cv2.rectangle(img, (xx,yy), (xx1, yy1), (0,255,0), 2)\n","            '''\n","            #target_offset = target_calculation(assigned_anchor, current_box, scale)\n","            #target_offsets.append(target_offset)\n","\n","      #plt.imshow(img)\n","      noobj_scores = torch.cat( (pred_s[pred_s_to_loss==1], pred_m[pred_m_to_loss==1], pred_b[pred_b_to_loss==1] ))\n","      noobj_loss = F.binary_cross_entropy_with_logits(nn.functional.sigmoid(noobj_scores.to('cuda')),\n","                                                      torch.zeros_like(noobj_scores, device='cuda'), )\n","      noobj_batch_loss += noobj_loss\n","      obj_loss_s, obj_loss_m, obj_loss_b = 0,0,0\n","      if pred_offsets_s or pred_offsets_m or pred_offsets_b:\n","        if pred_offsets_s:\n","          pred_offsets_s = torch.stack(pred_offsets_s)\n","          obj_loss_s = F.binary_cross_entropy_with_logits(nn.functional.sigmoid(pred_offsets_s[:,4]),\n","                                  torch.ones_like(pred_offsets_s[:,4], device=pred_offsets_s.device), )* 4.0\n","          target_offsets_s = torch.stack(target_offsets_s)\n","          xy_loss = F.mse_loss(nn.functional.sigmoid(pred_offsets_s[:,:2]), target_offsets_s[:,:2], reduction='sum')\n","          wh_loss = F.mse_loss(torch.exp(pred_offsets_s[:,2:4]), target_offsets_s[:,2:4], reduction='sum')\n","          offset_loss = (xy_loss+wh_loss)/target_offsets_s.numel()\n","          #print('s',offset_loss)\n","          offsets_batch_loss += offset_loss\n","\n","        if pred_offsets_m:\n","          pred_offsets_m = torch.stack(pred_offsets_m)\n","          obj_loss_m = F.binary_cross_entropy_with_logits(nn.functional.sigmoid(pred_offsets_m[:,4]),\n","                                  torch.ones_like(pred_offsets_m[:,4], device=pred_offsets_m.device))\n","          target_offsets_m = torch.stack(target_offsets_m)\n","          xy_loss = F.mse_loss(nn.functional.sigmoid(pred_offsets_m[:,:2]), target_offsets_m[:,:2], reduction='sum')\n","          wh_loss = F.mse_loss(torch.exp(pred_offsets_m[:,2:4]), target_offsets_m[:,2:4], reduction='sum')\n","          offset_loss = (xy_loss + wh_loss)/target_offsets_m.numel()\n","          #print('m',offset_loss)\n","          offsets_batch_loss+=offset_loss\n","\n","        if pred_offsets_b:\n","          pred_offsets_b = torch.stack(pred_offsets_b)\n","          obj_loss_b = F.binary_cross_entropy_with_logits(nn.functional.sigmoid(pred_offsets_b[:,4]),\n","                                  torch.ones_like(pred_offsets_b[:,4], device=pred_offsets_b.device)) * 0.4\n","          target_offsets_b = torch.stack(target_offsets_b)\n","          xy_loss = F.mse_loss(nn.functional.sigmoid(pred_offsets_b[:,:2]), target_offsets_b[:,:2], reduction='sum')\n","          wh_loss = F.mse_loss(torch.exp(pred_offsets_b[:,2:4]), target_offsets_b[:,2:4], reduction='sum')\n","          offset_loss = (xy_loss + wh_loss)/target_offsets_b.numel()\n","          #print('b',offset_loss)\n","          offsets_batch_loss+=offset_loss\n","\n","        obj_batch_loss += (obj_loss_s + obj_loss_m + obj_loss_b)\n","\n","  return {'offset_loss':offsets_batch_loss/16, 'obj_loss':obj_batch_loss/16 , 'noobj_loss':noobj_batch_loss/16}\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZSjBgquflEuA"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WMgkOvaMekiC"},"outputs":[],"source":["def calc_iou(box, anchors):\n","  anchors_area = ( anchors[:,2] - anchors[:,0] ) * ( anchors[:,3] - anchors[:,1] )\n","  boxes_area   = box[:,2] * box[:,3]\n","  upper_left_intersection = torch.max(anchors[:,:2].unsqueeze(1), (box[:,:2] - box[:,2:]/2))\n","  lower_right_intersection = torch.min(anchors[:,2:].unsqueeze(1), (box[:,:2] + box[:,2:]/2))\n","  intersection_dimension = (lower_right_intersection - upper_left_intersection).clamp(min=0)\n","  intersection_area = intersection_dimension[:,:,0] * intersection_dimension[:,:,1]\n","  union_area = anchors_area.unsqueeze(1) + boxes_area - intersection_area\n","  return intersection_area/union_area\n","\n","def anchors_assignment(box, anchors, cells_location, used_anchor_location_cell, used_cell, idx):\n","    neg_anchors = [0,1,2,3,4,5,6,7,8]\n","    pos_anchor = None\n","    triger = False\n","    discarded_anchors = []\n","    ignore_anchors = []\n","    confidence_supposed_pos = None\n","    cell_location = None\n","    ious = calc_iou(box, anchors)\n","    ious = torch.transpose(ious, 0, 1)\n","\n","    values, indices = torch.sort( ious, descending=True)\n","    values, indices = values[0], indices[0]\n","    greater_than_half = torch.where(values >= 0.7)[0]\n","    ignore_anchors = indices[greater_than_half]\n","    for num in range(len(indices)):\n","      if values[num] > 0.3:\n","        pos_anchor = indices[num]\n","        cell_index = int(pos_anchor/3)\n","        anchor_location_in_cell = [cells_location[cell_index], pos_anchor ]\n","        cell_location = cells_location[cell_index]\n","        if anchor_location_in_cell in used_anchor_location_cell:\n","          continue\n","        else:\n","          break\n","      else:\n","        return None, None, None, ignore_anchors\n","\n","    return pos_anchor, anchor_location_in_cell, cell_location, ignore_anchors\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ku_w5Kbz61EF"},"outputs":[],"source":["def target_calculation(assigned_anchors, assigned_bbox, scale):\n","\n","    for anchor, box in zip(assigned_anchors, assigned_bbox):\n","        x = (box[0] - ( int(box[0]/scale) * scale))/scale\n","        y = (box[1] - ( int(box[1]/scale) * scale))/scale\n","\n","        anchor_w = anchor[2] - anchor[0]\n","        anchor_h = anchor[3] - anchor[1]\n","\n","        w = box[2]/anchor_w\n","        h = box[3]/anchor_h\n","\n","        target = torch.tensor([x, y, w, h], dtype=torch.float32).to('cuda')\n","\n","\n","    return target\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42708,"status":"ok","timestamp":1693249608307,"user":{"displayName":"HAITHAM AL-TOSAIMI","userId":"14079608149427840165"},"user_tz":-120},"id":"rGhoaf7hmVGO","outputId":"342552b4-736c-4596-8d3e-0d784917d836"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2297,"status":"ok","timestamp":1693249612438,"user":{"displayName":"HAITHAM AL-TOSAIMI","userId":"14079608149427840165"},"user_tz":-120},"id":"KislBHadkeyj","outputId":"2c951c3f-0493-41a7-ebc5-54f0317b1c72"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  /content/gdrive/MyDrive/wider_face_split.zip\n","   creating: wider_face_split/\n","  inflating: wider_face_split/readme.txt  \n","  inflating: wider_face_split/wider_face_test.mat  \n","  inflating: wider_face_split/wider_face_test_filelist.txt  \n","  inflating: wider_face_split/wider_face_train.mat  \n","  inflating: wider_face_split/wider_face_train_bbx_gt.txt  \n","  inflating: wider_face_split/wider_face_val.mat  \n","  inflating: wider_face_split/wider_face_val_bbx_gt.txt  \n"]}],"source":["!unzip /content/gdrive/MyDrive/wider_face_split.zip\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZ3nU_tskfLi"},"outputs":[],"source":["\n","!unzip /content/gdrive/MyDrive/WIDER_train.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RH2poGyxrcnF"},"outputs":[],"source":["\n","from PIL import Image\n","import torchvision\n","import numpy as np\n","import cv2\n","import torch\n","\n","class LoadDataSet(torch.utils.data.Dataset):\n","  def __init__(self, annotation_path, images_path, transforms):\n","    self.images_path_list = images_path\n","    self.annotation_path_list = annotation_path\n","    self.transform = transforms\n","    self.size = len(self.images_path_list)\n","    print(self.size)\n","\n","  def __getitem__(self, idx):\n","    Transform = torchvision.transforms.Normalize(mean=[0.485,0.456,0.406],\n","                                                 std=[0.229,0.224,0.225])\n","\n","    img_path = '/content/WIDER_train/images/'+self.images_path_list[idx]\n","    gt_boxes = self.annotation_path_list[idx]\n","    img = Image.open(img_path)\n","    img = np.asarray(img)\n","    img_size = img.shape\n","    image = cv2.resize(img/255., (416,416), interpolation=cv2.INTER_AREA)\n","    image = torch.as_tensor(image, dtype=torch.float32).permute(2,0,1)\n","    image = Transform(image)\n","    scalar = torch.tensor([1, 416/img_size[1], 416/img_size[0], 416/img_size[1], 416/img_size[0]], dtype=torch.float32)\n","\n","    boxes = []\n","    scale_small = 8\n","    scale_medium = 16\n","    scale_big = 32\n","\n","\n","    for box in gt_boxes:\n","        s_box = torch.tensor(box, dtype=torch.float32)*scalar\n","\n","        x_ctr = (s_box[3] + s_box[1])/2\n","        w     = (s_box[3] - s_box[1])\n","        #print(\"x_ctr\", x_ctr)\n","        x0_small_cell = int(x_ctr/scale_small)\n","        x0_medium_cell = int(x_ctr/scale_medium)\n","        x0_big_cell = int(x_ctr/scale_big)\n","\n","\n","        y_ctr = (s_box[4] + s_box[2])/2\n","        h     = (s_box[4] - s_box[2])\n","        #print(\"y_ctr\", y_ctr)\n","        y0_small_cell = int(y_ctr/scale_small)\n","        y0_medium_cell = int(y_ctr/scale_medium)\n","        y0_big_cell = int(y_ctr/scale_big)\n","\n","\n","        s_box[1] = x_ctr\n","        s_box[2] = y_ctr\n","        s_box[3] = w\n","        s_box[4] = h\n","\n","        boxes.append([1, [(x0_small_cell, y0_small_cell),(x0_medium_cell, y0_medium_cell), (x0_big_cell, y0_big_cell)], s_box[1:]])\n","\n","    return image, boxes, img_path\n","\n","  def __len__(self):\n","    return self.size\n","\n","def collate_fn(batch):\n","  images = []\n","  boxes = []\n","  for data in batch:\n","    images.append(data[0])\n","    boxes.append(data[1])\n","  return torch.stack(images, dim=0), boxes, data[2]\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uASR-uX0k-FT"},"outputs":[],"source":["file = open('/content/wider_face_split/wider_face_train_bbx_gt.txt')\n","lista=[]\n","inside_list=[]\n","names=[]\n","# this parameter is used to generate the anchors\n","all_boxes = []\n","triger=0\n","\n","for idx, line in enumerate(file.readlines()):\n","    if line[-4:]==\"jpg\\n\":\n","       names.append(line[:-1])\n","       if (inside_list==[] or triger==1) and idx!=0:\n","          names.pop(len(names)-2)\n","          inside_list = []\n","          triger = 0\n","          continue\n","       if idx!=0 and inside_list!=[]:\n","          lista.append(inside_list)\n","          inside_list = []\n","    if line[-4:]!='jpg\\n' and len(line)>15:\n","       num_list = line.strip()\n","       num_str = num_list.split()\n","       x1 = int(num_str[0])\n","       y1 = int(num_str[1])\n","       x2 = int(num_str[0]) + int(num_str[2])\n","       y2 = int(num_str[1]) + int(num_str[3])\n","       if num_str[2]!='0' and num_str[3]!='0' and num_str[7]!='1' and (x2-x1)>20 and (x2-x1)<1200 and (y2-y1)>20 and (y2-y1)<1200:\n","          array_int = [1, x1, y1, x2, y2]\n","          all_boxes.append(array_int[1:])\n","          inside_list.append(array_int)\n","       else:\n","          triger=1\n","    if idx == 185183:\n","       if inside_list!=[] and triger==0:\n","          lista.append(inside_list)\n","       elif inside_list==[] and triger==1:\n","          names.pop()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1693249651631,"user":{"displayName":"HAITHAM AL-TOSAIMI","userId":"14079608149427840165"},"user_tz":-120},"id":"arF69zm-k-a3","outputId":"5c68537a-e2fa-461d-e49b-a042ed7892cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["9074\n"]}],"source":["#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","dataset = LoadDataSet(annotation_path=lista, images_path=names, transforms=None)\n","data_loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=collate_fn, drop_last=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8gqOs24Ysu0X"},"outputs":[],"source":["import torch\n","import numpy as np\n","new_centroids = torch.tensor([[  0.0000,   0.0000,  13.2136,  21.0693],\n","        [  0.0000,   0.0000,  18.2718,  33.5538],\n","        [  0.0000,   0.0000,  28.8336,  45.1136],\n","        [  0.0000,   0.0000,  36.9599,  76.1135],\n","        [  0.0000,   0.0000,  55.4889,  52.9748],\n","        [  0.0000,   0.0000,  57.9636, 119.5746],\n","        [  0.0000,   0.0000,  96.7757,  97.8682],\n","        [  0.0000,   0.0000, 118.6441, 183.7684],\n","        [  0.0000,   0.0000, 199.0680, 252.7008]], dtype=torch.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PMk2_dlesvTz"},"outputs":[],"source":["\n","\n","anchors_small = []\n","anchors_medium = []\n","anchors_big = []\n","\n","for i in range(52):\n","  for j in range(52):\n","    anchors_per_cell_small = []\n","    anchors_per_cell_medium = []\n","    anchors_per_cell_big = []\n","    for k, box in enumerate(new_centroids[:3]):\n","        if i<52 and j<52:\n","          anchor = [ (i)*8 + 4 - int((box[2] - box[0])/2), (j)*8 + 4 - int((box[3] - box[1])/2),\n","                    (i)*8 + 4 + int((box[2] - box[0])/2), (j)*8 + 4 + int((box[3] - box[1])/2)]\n","          if sum(torch.tensor(anchor) >= 0)==4:\n","            anchors_per_cell_small.append(anchor)\n","          else:\n","            anchors_per_cell_small.append([0.0, 0.0, 0.0, 0.0])\n","\n","    for k, box in enumerate(new_centroids[3:6]):\n","      if i<26 and j<26:\n","        anchor = [ (i)*16 + 8 - int((box[2] - box[0])/2), (j)*16 + 8 - int((box[3] - box[1])/2),\n","                  (i)*16 + 8 + int((box[2] - box[0])/2), (j)*16 + 8 + int((box[3] - box[1])/2)]\n","        if sum(torch.tensor(anchor) >= 0)==4:\n","          anchors_per_cell_medium.append(anchor)\n","        else:\n","          anchors_per_cell_medium.append([0.0, 0.0, 0.0, 0.0])\n","\n","\n","    for k, box in enumerate(new_centroids[6:]):\n","        if i<13 and j<13:\n","          anchor = [ (i)*32 + 16 - int((box[2]- box[0])/2), (j)*32 + 16 - int((box[3] - box[1])/2),\n","                    (i)*32+16 + int((box[2]- box[0])/2), (j)*32 + 16 + int((box[3] - box[1])/2)]\n","          if sum(torch.tensor(anchor) >= 0)==4:\n","            anchors_per_cell_big.append(anchor)\n","          else:\n","            anchors_per_cell_big.append([0.0, 0.0, 0.0, 0.0])\n","\n","\n","    if i<52 and j<52:\n","          anchors_small.append(anchors_per_cell_small)\n","\n","    if i<26 and j<26:\n","        anchors_medium.append(anchors_per_cell_medium)\n","\n","    if i<13 and j<13:\n","        anchors_big.append(anchors_per_cell_big)\n","\n","all_anchors = {'small':anchors_small, 'medium':anchors_medium, 'big':anchors_big}\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0mwClCaxfeTX"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JRdEQMTT1hCr"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UeC1heVO1hFS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ALFxBSPM1hHs"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9opvPjgq1hJt"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3xeJ1HyT1hL5"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TS2MbakV1hOB"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}