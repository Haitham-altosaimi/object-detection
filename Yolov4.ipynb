{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNxB0MDqekRfbeDDShIn800"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"irAVsQhdBJrz"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DEp-bp2_z8Tn"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class res_block(nn.Module):\n","  def __init__(self, in_channels=32, out_channels=32, stride=1, downsample=None, expansions=1):\n","    super(res_block, self).__init__()\n","    in_channels = in_channels\n","    out_channels = out_channels\n","    self.conv1 = nn.Sequential(\n","                    nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, ),\n","                    nn.BatchNorm2d(out_channels),\n","                    nn.Mish())\n","    self.conv2 = nn.Sequential(\n","                    nn.Conv2d(out_channels, in_channels, kernel_size=3, stride=1, padding=1),\n","                    nn.BatchNorm2d(in_channels),\n","                    nn.Mish())\n","  def forward(self, x):\n","      residual = x\n","      out = self.conv1(x)\n","\n","      out = self.conv2(out)\n","\n","      out += residual\n","\n","\n","      return out\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FUl6lgN_FItU"},"outputs":[],"source":["from torch.nn.modules.activation import LeakyReLU\n","class cspdarknet(nn.Module):\n","  def __init__(self, ):\n","    super(cspdarknet, self).__init__()\n","    block = res_block\n","    self.conv0 = nn.Sequential(\n","                    nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n","                    nn.BatchNorm2d(32),\n","                    nn.Mish(),)\n","    self.downsample1 = nn.Sequential(\n","        nn.Conv2d(32 ,64, kernel_size=3, stride=2, padding=1,),\n","        nn.BatchNorm2d(64),\n","        nn.Mish()\n","\n","    )\n","    self.block0 = self._make_block0()\n","\n","    self.downsample2 = nn.Sequential(\n","        nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(128),\n","        nn.Mish()\n","    )\n","    self.conv1 = nn.Sequential(\n","        nn.Conv2d(128, 64, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(64),\n","        nn.Mish()\n","    )\n","    self.conv2 = nn.Sequential(\n","        nn.Conv2d(128, 64, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(64),\n","        nn.Mish()\n","    )\n","\n","    self.block1 = self._make_block(block, in_cha=64, out_cha=64, repeats = 2, expansion=2)\n","    self.convb1 = nn.Sequential(\n","        nn.Conv2d(64, 64, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(64),\n","        nn.Mish())\n","\n","    self.convb11 = nn.Sequential(\n","        nn.Conv2d(128, 128, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(128),\n","        nn.Mish()\n","    )\n","    self.downsample3 = nn.Sequential(\n","        nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish()\n","    )\n","    self.conv3 = nn.Sequential(\n","        nn.Conv2d(256, 128, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(128),\n","        nn.Mish()\n","    )\n","    self.conv4 = nn.Sequential(\n","        nn.Conv2d(256, 128, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(128),\n","        nn.Mish()\n","    )\n","    self.block2 = self._make_block(block, in_cha=128, out_cha=128,repeats=8, expansion=4)\n","    self.convb2 = nn.Sequential(\n","        nn.Conv2d(128, 128, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(128),\n","        nn.Mish()\n","    )\n","    self.convb22 = nn.Sequential(\n","        nn.Conv2d(256, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish()\n","    )\n","    self.downsample4 = nn.Sequential(\n","        nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish()\n","    )\n","    self.conv5 = nn.Sequential(\n","        nn.Conv2d(512, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish()\n","    )\n","    self.conv6 = nn.Sequential(\n","        nn.Conv2d(512, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish()\n","    )\n","    self.block3 = self._make_block(block, in_cha=256, out_cha=256, repeats=8, expansion=8)\n","    self.convb3 = nn.Sequential(\n","        nn.Conv2d(256, 256, kernel_size=1, stride=1,),\n","        nn.BatchNorm2d(256),\n","        nn.Mish()\n","    )\n","    self.convb33 = nn.Sequential(\n","        nn.Conv2d(512, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish()\n","    )\n","    self.downsample5 = nn.Sequential(\n","        nn.Conv2d(512, 1024, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(1024),\n","        nn.Mish()\n","    )\n","\n","    self.conv7 = nn.Sequential(\n","        nn.Conv2d(1024, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish()\n","    )\n","    self.conv8 = nn.Sequential(\n","        nn.Conv2d(1024, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish()\n","    )\n","    self.block4 = self._make_block(block, in_cha=512, out_cha=512, repeats=4, expansion=16)\n","    self.convb4 = nn.Sequential(\n","        nn.Conv2d(512, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish()\n","    )\n","    self.convb44 = nn.Sequential(\n","        nn.Conv2d(1024, 1024, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(1024),\n","        nn.Mish()\n","    )\n","\n","  def _make_block0(self, ):\n","    return nn.Sequential(\n","        nn.Conv2d(64, 32, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(32),\n","        nn.Mish(),\n","        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(64),\n","        nn.Mish()\n","    )\n","  def _make_block(self, block, in_cha=64, out_cha=64, repeats=0, expansion=0):\n","    layers = []\n","\n","    for i in range(repeats):\n","      layers.append(block(in_channels=in_cha, out_channels=out_cha ,expansions=expansion))\n","\n","    return nn.Sequential(*layers)\n","\n","  def forward(self, x):\n","    x = self.conv0(x)\n","    down_s1 = self.downsample1(x)\n","\n","    ## block0\n","    b0 = self.block0(down_s1)\n","    b0 =  down_s1 + b0\n","    down_s2 = self.downsample2(b0)\n","\n","    ## block1\n","\n","    x0 = self.conv1(down_s2)\n","    x1 = self.conv2(down_s2)\n","\n","    b1 = self.block1(x1)\n","    b1 = self.convb1(b1)\n","    b1 = torch.cat((b1,x0), dim=1)\n","    b1 = self.convb11(b1)\n","    down_s3 = self.downsample3(b1)\n","    ##block2\n","\n","    x0 = self.conv3(down_s3)\n","    x1 = self.conv4(down_s3)\n","\n","    b2 = self.block2(x1)\n","    b2 = self.convb2(b2)\n","\n","    b2 = torch.cat((b2, x0), dim=1)\n","    b2 = self.convb22(b2)\n","    down_s4 = self.downsample4(b2)\n","    ## block3\n","\n","    x0 = self.conv5(down_s4)\n","    x1 = self.conv6(down_s4)\n","\n","\n","    b3 = self.block3(x1)\n","    b3 = self.convb3(b3)\n","\n","    b3 = torch.cat((b3, x0), dim=1)\n","    b3 = self.convb33(b3)\n","    down_s5 = self.downsample5(b3)\n","    ## block4\n","\n","    x0 = self.conv7(down_s5)\n","    x1 = self.conv8(down_s5)\n","\n","    b4 = self.block4(x1)\n","    b4 = self.convb4(b4)\n","\n","    b4 = torch.cat((b4,x0), dim=1)\n","    b4 = self.convb44(b4)\n","\n","\n","    return {'b4':b4, 'b3':b3, 'b2':b2}\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TXThmykXz7-K"},"outputs":[],"source":["import torch.nn.functional as F\n","class Yolov4(nn.Module):\n","  def __init__(self, ):\n","    super(Yolov4, self).__init__()\n","    self.cspdarknet = cspdarknet()\n","    self.conv_spp1 = nn.Sequential(\n","        nn.Conv2d(1024, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish()\n","    )\n","    self.conv_spp2 = self._make_into_spp_convs()\n","    self.spp1 = self._make_spp(5)\n","    self.spp2 = self._make_spp(9)\n","    self.spp3 = self._make_spp(13)\n","    self.spp_conv = nn.Sequential(\n","        nn.Conv2d(2048, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish(),\n","        nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish()\n","    )\n","    self.conv1 = nn.Sequential(\n","        nn.Conv2d(1024, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish()\n","    )\n","    self.conv2 = nn.Sequential(\n","        nn.Conv2d(512, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish()\n","    )\n","\n","    self.conv3 = nn.Sequential(\n","        nn.Conv2d(512, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish()\n","    )\n","    self.conv4 = nn.Sequential(\n","        nn.Conv2d(512, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish()\n","    )\n","    self.conv5 = nn.Sequential(\n","        nn.Conv2d(256, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish()\n","    )\n","    self.convv2 = nn.Sequential(\n","        nn.Conv2d(256, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish(),\n","        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish(),\n","        nn.Conv2d(256, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish(),\n","        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish()\n","    )\n","    self.conv6 = nn.Sequential(\n","        nn.Conv2d(512, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish()\n","    )\n","    self.conv7 = nn.Sequential(\n","        nn.Conv2d(256, 128, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(128),\n","        nn.Mish()\n","    )\n","    self.conv8 = nn.Sequential(\n","        nn.Conv2d(256, 128, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(128),\n","        nn.Mish()\n","    )\n","    self.conv9 = nn.Sequential(\n","        nn.Conv2d(256, 128, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(128),\n","        nn.Mish()\n","    )\n","    self.conv10 = nn.Sequential(\n","        nn.Conv2d(128, 128, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(128),\n","        nn.Mish()\n","    )\n","\n","    self.convv3 = nn.Sequential(\n","        nn.Conv2d(128, 128, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(128),\n","        nn.Mish(),\n","        nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(128),\n","        nn.Mish(),\n","        nn.Conv2d(128, 128, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(128),\n","        nn.Mish(),\n","        nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(128),\n","        nn.Mish()\n","    )\n","    self.conv11 = nn.Sequential(\n","        nn.Conv2d(256, 128, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(128),\n","        nn.Mish()\n","    )\n","    self.downsample_one = nn.Sequential(\n","        nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish()\n","    )\n","    self.conv12 = nn.Sequential(\n","        nn.Conv2d(512, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish()\n","    )\n","    self.convv4 = nn.Sequential(\n","        nn.Conv2d(256, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish(),\n","        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish(),\n","        nn.Conv2d(256, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish(),\n","        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish()\n","    )\n","    self.conv13 = nn.Sequential(\n","        nn.Conv2d(256, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish()\n","    )\n","    self.conv14 = nn.Sequential(\n","        nn.Conv2d(512, 256, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(256),\n","        nn.Mish()\n","    )\n","\n","    self.downsample_two = nn.Sequential(\n","        nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish()\n","    )\n","\n","    self.conv15 = nn.Sequential(\n","        nn.Conv2d(1024, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish()\n","    )\n","\n","    self.convv5 = nn.Sequential(\n","        nn.Conv2d(512, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish(),\n","        nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish(),\n","        nn.Conv2d(512, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish(),\n","        nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish()\n","    )\n","    self.conv16 = nn.Sequential(\n","        nn.Conv2d(512, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish(),\n","    )\n","    self.conv17 = nn.Sequential(\n","        nn.Conv2d(1024, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish()\n","    )\n","    self.output1 = self._final_layer(512, 1024)\n","    self.output2 = self._final_layer(256, 512)\n","    self.output3 = self._final_layer(128, 256)\n","\n","  def _make_into_spp_convs(self):\n","    return nn.Sequential(\n","        nn.Conv2d(1024, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish(),\n","        nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish(),\n","        nn.Conv2d(512, 512, kernel_size=1, stride=1),\n","        nn.BatchNorm2d(512),\n","        nn.Mish())\n","\n","  def _final_layer(self, input, output):\n","      return nn.Sequential(\n","          nn.Conv2d(input ,output, kernel_size=3, stride=1,padding=1 ),\n","          nn.BatchNorm2d(output),\n","          nn.Mish(),\n","          nn.Conv2d(output, 15, kernel_size=1, stride=1)\n","      )\n","\n","\n","  def _make_spp(self, size):\n","    return nn.MaxPool2d(kernel_size=size, stride=1, padding=size//2)\n","\n","\n","\n","  def forward(self, images, targets, anchors):\n","      ## feature extraction\n","      x = self.cspdarknet(images)\n","\n","      ## spp start\n","      x0 = self.conv_spp1(x['b4'])\n","      x1 = self.conv_spp2(x['b4'])\n","      spp1 = self.spp1(x1)\n","      spp2 = self.spp2(x1)\n","      spp3 = self.spp3(x1)\n","      b4 = torch.cat((spp1, spp2, spp3, x1), dim=1)\n","      b4 = self.spp_conv(b4)\n","      b4 = torch.cat((b4, x0), dim=1)\n","      b4 = self.conv1(b4)\n","      ## ssp finish\n","\n","      ## pan start\n","      b4_route = self.conv2(b4)\n","      upsampled_one = F.interpolate(b4_route, (26, 26), mode='nearest')\n","      b3 = self.conv3(x['b3'])\n","      concat_one = torch.cat((b3, upsampled_one), dim=1)\n","      b3 = self.conv4(concat_one)\n","      b3_route = self.convv2(b3)\n","      b3 = self.conv5(b3)\n","      b3 = torch.cat((b3, b3_route), dim=1)\n","      b3 = self.conv6(b3)\n","\n","      b3_route = self.conv7(b3)\n","      upsampled_two = F.interpolate(b3_route, (52, 52), mode='nearest')\n","      b2 = self.conv8(x['b2'])\n","      concat_two = torch.cat((b2, upsampled_two), dim=1)\n","      b2 = self.conv9(concat_two)\n","      b2_route = self.convv3(b2)\n","      b2 = self.conv10(b2)\n","      b2 = torch.cat((b2_route, b2), dim=1)\n","      b2 = self.conv11(b2)\n","\n","\n","      downsample_one = self.downsample_one(b2)\n","      concat_pan_one = torch.cat((downsample_one, b3), dim=1)\n","      b3 = self.conv12(concat_pan_one)\n","      b3_rout = self.convv4(b3)\n","      b3 = self.conv13(b3)\n","      b3 = torch.cat((b3_rout, b3), dim=1)\n","      b3 = self.conv14(b3)\n","\n","      downsample_two = self.downsample_two(b3)\n","      concat_pan_tow = torch.cat((downsample_two, b4), dim=1)\n","      b4 = self.conv15(concat_pan_tow)\n","      b4_route = self.convv5(b4)\n","      b4 = self.conv16(b4)\n","      b4 = torch.cat((b4_route, b4), dim=1)\n","      b4 = self.conv17(b4)\n","      ## pan finished\n","\n","      output_s = self.output3(b2).permute(0,2,3,1).view(-1,52,52,3,5)\n","      output_m = self.output2(b3).permute(0,2,3,1).view(-1,26,26,3,5)\n","      output_b = self.output1(b4).permute(0,2,3,1).view(-1,13,13,3,5)\n","\n","      loss_outputs = output_preprocessing(output_s, output_m, output_b, targets, images, anchors)\n","\n","      return (loss_outputs['offset_loss']*2.0 + loss_outputs['obj_loss']+\n","              loss_outputs['noobj_loss']*0.2), loss_outputs\n","\n","\n","\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"RyB1krCapwZi"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ei9cjOHRY0Ij"},"outputs":[],"source":["from tqdm import tqdm\n","from functools import partial\n","tqdm = partial(tqdm, position=0, leave=True)\n","import torch\n","import numpy as np\n","import time\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","\n","def train_epocs(model, optimizer, data_loader, devie, all_anchors ,epochs=30,training_state=False ):\n","\n","    for epoch in range(epochs):\n","        if epoch==30:\n","           parameters = model.parameters()\n","           optimizer = torch.optim.SGD(parameters, lr = 0.000002,\n","                                       momentum=0.99)\n","        total = 0\n","        sum_loss = 0\n","        sum_loss_classifier = 0\n","        sum_loss_offsets = 0\n","        sum_loss_noobj = 0\n","        sum_loss_obj = 0\n","\n","        iteration_num = 0\n","\n","        for i, data in enumerate(tqdm(data_loader)):\n","            images = data[0].to(device)\n","            targets = data[1]\n","            batch_length = len(images)\n","            ### gradient tracking\n","            if not training_state:\n","               with torch.no_grad():\n","                  model.eval()\n","                  output = model(images, targets = targets, anchors = all_anchors)\n","            else:\n","                 model.train()\n","                 output = model(images, targets, all_anchors)\n","            Final_loss = output[0]\n","            Final_loss.backward()\n","            if training_state and i%4==0 and i>0:\n","               optimizer.step()\n","               optimizer.zero_grad()\n","\n","\n","            iteration_num += 1\n","            total += batch_length\n","\n","            sum_loss += output[0]\n","            #sum_loss_classifier += output[1]\n","            sum_loss_offsets += output[1]['offset_loss']\n","            sum_loss_noobj += output[1]['noobj_loss']\n","            sum_loss_obj += output[1]['obj_loss']\n","\n","            if iteration_num % 50 == 0:\n","\n","                train_loss = sum_loss/total\n","                train_loss_classifier = sum_loss_classifier/total\n","                train_loss_offsets = sum_loss_offsets/total\n","                train_loss_noobj = sum_loss_noobj/total\n","                train_loss_obj = sum_loss_obj/total\n","                print(\"loss %.6f classifer %.6f regressor %.6f noobj_loss %.6f obj_loss %.6f \"%\n","                      (train_loss, train_loss_classifier, train_loss_offsets, train_loss_noobj, train_loss_obj))\n","                total = 0.0\n","                sum_loss= 0.0\n","                sum_loss_classifier = 0.0\n","                sum_loss_offsets = 0.0\n","                sum_loss_noobj = 0.0\n","                sum_loss_obj = 0.0\n","\n","\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5405,"status":"ok","timestamp":1692720232205,"user":{"displayName":"Hemo Hamo","userId":"14653600239742849398"},"user_tz":-120},"id":"QH1IuCwB7SQ9","outputId":"7a9b80ab-9c29-4568-b5c9-820d67253356"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","model = Yolov4().to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3 , momentum = 0.949)\n","print(device)\n"]},{"cell_type":"code","source":["model"],"metadata":{"id":"FmHytZGk8lRm"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tF153O-u6_6p","outputId":"da654447-7567-4523-f137-a0d83d2f1c26"},"outputs":[{"output_type":"stream","name":"stderr","text":["  9%|▉         | 50/567 [00:52<08:51,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["loss 0.041675 classifer 0.000000 regressor 0.011772 noobj_loss 0.017028 obj_loss 0.014725 \n"]},{"output_type":"stream","name":"stderr","text":[" 18%|█▊        | 100/567 [01:39<07:39,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["loss 0.031029 classifer 0.000000 regressor 0.006878 noobj_loss 0.017569 obj_loss 0.013760 \n"]},{"output_type":"stream","name":"stderr","text":[" 26%|██▋       | 150/567 [02:23<06:48,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["loss 0.028533 classifer 0.000000 regressor 0.006101 noobj_loss 0.018511 obj_loss 0.012628 \n"]},{"output_type":"stream","name":"stderr","text":[" 35%|███▌      | 200/567 [03:08<06:17,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["loss 0.027916 classifer 0.000000 regressor 0.006191 noobj_loss 0.019595 obj_loss 0.011614 \n"]},{"output_type":"stream","name":"stderr","text":[" 44%|████▍     | 250/567 [03:53<05:10,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["loss 0.025707 classifer 0.000000 regressor 0.005622 noobj_loss 0.020984 obj_loss 0.010267 \n"]},{"output_type":"stream","name":"stderr","text":[" 53%|█████▎    | 300/567 [04:37<04:21,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["loss 0.025282 classifer 0.000000 regressor 0.005711 noobj_loss 0.022299 obj_loss 0.009401 \n"]},{"output_type":"stream","name":"stderr","text":[" 62%|██████▏   | 350/567 [05:21<03:34,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["loss 0.025942 classifer 0.000000 regressor 0.006520 noobj_loss 0.023708 obj_loss 0.008161 \n"]},{"output_type":"stream","name":"stderr","text":[" 71%|███████   | 400/567 [06:06<02:56,  1.06s/it]"]},{"output_type":"stream","name":"stdout","text":["loss 0.024483 classifer 0.000000 regressor 0.005968 noobj_loss 0.024832 obj_loss 0.007580 \n"]},{"output_type":"stream","name":"stderr","text":[" 79%|███████▉  | 450/567 [06:51<01:57,  1.00s/it]"]},{"output_type":"stream","name":"stdout","text":["loss 0.022140 classifer 0.000000 regressor 0.005086 noobj_loss 0.025905 obj_loss 0.006786 \n"]},{"output_type":"stream","name":"stderr","text":[" 88%|████████▊ | 500/567 [07:35<01:05,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["loss 0.022075 classifer 0.000000 regressor 0.005241 noobj_loss 0.026922 obj_loss 0.006210 \n"]},{"output_type":"stream","name":"stderr","text":[" 97%|█████████▋| 550/567 [08:18<00:16,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["loss 0.022571 classifer 0.000000 regressor 0.005493 noobj_loss 0.027369 obj_loss 0.006111 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 567/567 [08:33<00:00,  1.10it/s]\n","  9%|▉         | 50/567 [00:44<08:56,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["loss 0.025190 classifer 0.000000 regressor 0.006952 noobj_loss 0.028415 obj_loss 0.005602 \n"]},{"output_type":"stream","name":"stderr","text":[" 18%|█▊        | 100/567 [01:28<07:47,  1.00s/it]"]},{"output_type":"stream","name":"stdout","text":["loss 0.021939 classifer 0.000000 regressor 0.005414 noobj_loss 0.028627 obj_loss 0.005385 \n"]},{"output_type":"stream","name":"stderr","text":[" 26%|██▋       | 150/567 [02:12<07:05,  1.02s/it]"]},{"output_type":"stream","name":"stdout","text":["loss 0.021592 classifer 0.000000 regressor 0.005351 noobj_loss 0.029334 obj_loss 0.005023 \n"]},{"output_type":"stream","name":"stderr","text":[" 35%|███▌      | 200/567 [02:57<05:58,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["loss 0.021461 classifer 0.000000 regressor 0.005348 noobj_loss 0.030137 obj_loss 0.004737 \n"]},{"output_type":"stream","name":"stderr","text":[" 44%|████▍     | 250/567 [03:41<05:06,  1.04it/s]"]},{"output_type":"stream","name":"stdout","text":["loss 0.022305 classifer 0.000000 regressor 0.005851 noobj_loss 0.030994 obj_loss 0.004404 \n"]},{"output_type":"stream","name":"stderr","text":[" 53%|█████▎    | 300/567 [04:25<04:34,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["loss 0.022464 classifer 0.000000 regressor 0.005884 noobj_loss 0.031449 obj_loss 0.004407 \n"]},{"output_type":"stream","name":"stderr","text":[" 62%|██████▏   | 350/567 [05:08<03:36,  1.00it/s]"]},{"output_type":"stream","name":"stdout","text":["loss 0.021906 classifer 0.000000 regressor 0.005726 noobj_loss 0.031706 obj_loss 0.004112 \n"]},{"output_type":"stream","name":"stderr","text":[" 71%|███████   | 400/567 [05:52<02:45,  1.01it/s]"]},{"output_type":"stream","name":"stdout","text":["loss 0.021494 classifer 0.000000 regressor 0.005465 noobj_loss 0.032612 obj_loss 0.004042 \n"]},{"output_type":"stream","name":"stderr","text":[" 79%|███████▉  | 450/567 [06:36<01:54,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["loss 0.020608 classifer 0.000000 regressor 0.005181 noobj_loss 0.033022 obj_loss 0.003641 \n"]},{"output_type":"stream","name":"stderr","text":[" 88%|████████▊ | 500/567 [07:20<01:09,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["loss 0.020958 classifer 0.000000 regressor 0.005395 noobj_loss 0.033225 obj_loss 0.003522 \n"]},{"output_type":"stream","name":"stderr","text":[" 97%|█████████▋| 550/567 [08:05<00:17,  1.01s/it]"]},{"output_type":"stream","name":"stdout","text":["loss 0.020447 classifer 0.000000 regressor 0.005031 noobj_loss 0.033708 obj_loss 0.003643 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 567/567 [08:20<00:00,  1.13it/s]\n","  9%|▉         | 50/567 [00:43<08:21,  1.03it/s]"]},{"output_type":"stream","name":"stdout","text":["loss 0.020664 classifer 0.000000 regressor 0.005314 noobj_loss 0.033775 obj_loss 0.003282 \n"]},{"output_type":"stream","name":"stderr","text":[" 18%|█▊        | 100/567 [01:28<07:36,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["loss 0.019914 classifer 0.000000 regressor 0.004922 noobj_loss 0.033937 obj_loss 0.003283 \n"]},{"output_type":"stream","name":"stderr","text":[" 26%|██▋       | 150/567 [02:12<07:14,  1.04s/it]"]},{"output_type":"stream","name":"stdout","text":["loss 0.020381 classifer 0.000000 regressor 0.005127 noobj_loss 0.034049 obj_loss 0.003317 \n"]},{"output_type":"stream","name":"stderr","text":[" 35%|███▌      | 200/567 [02:56<06:15,  1.02s/it]"]},{"output_type":"stream","name":"stdout","text":["loss 0.019968 classifer 0.000000 regressor 0.004840 noobj_loss 0.034510 obj_loss 0.003386 \n"]},{"output_type":"stream","name":"stderr","text":[" 44%|████▍     | 250/567 [03:39<05:11,  1.02it/s]"]},{"output_type":"stream","name":"stdout","text":["loss 0.020069 classifer 0.000000 regressor 0.005092 noobj_loss 0.035016 obj_loss 0.002882 \n"]},{"output_type":"stream","name":"stderr","text":[" 51%|█████     | 288/567 [04:13<04:10,  1.11it/s]"]}],"source":["train = train_epocs(model, optimizer, data_loader, device, all_anchors, epochs=20 ,training_state=True)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5xQYF-mopUcr"},"outputs":[],"source":["\n","def output_preprocessing(prediction_s, prediction_m,\n","                         prediction_b, gt_boxes, images, anchors):\n","\n","  noobj_batch_loss = 0\n","  obj_batch_loss = 0\n","  offsets_batch_loss = 0\n","  for pred_s, pred_m, pred_b, gt in zip(prediction_s, prediction_m, prediction_b, gt_boxes):\n","      pred_offsets = []\n","      target_offsets = []\n","      used_cell = []\n","      used_anchor_cell = []\n","      centroids = [ sample[1] for sample in gt ]\n","      boxes_in_image = torch.stack([ sample[2] for sample in gt])\n","\n","\n","      pred_s_to_loss = torch.zeros_like(pred_s, )\n","      pred_s_to_loss[:,:,:,4]=1\n","      pred_m_to_loss = torch.zeros_like(pred_m, )\n","      pred_m_to_loss[:,:,:,4]=1\n","      pred_b_to_loss = torch.zeros_like(pred_b,)\n","      pred_b_to_loss[:,:,:,4]=1\n","      #img = images[0].to(torch.device('cuda')).numpy().transpose(1,2,0).copy()\n","\n","      for idx, grid_cells in enumerate(centroids):\n","\n","          small_cell   = grid_cells[0]\n","          medium_cell  = grid_cells[1]\n","          big_cell     = grid_cells[2]\n","\n","          current_box  = boxes_in_image[idx].unsqueeze(0)\n","\n","          small_cell_anchors  = torch.tensor(anchors['small'][ small_cell[0]*52 + small_cell[1]])\n","          medium_cell_anchors = torch.tensor(anchors['medium'][ medium_cell[0]*26 + medium_cell[1]])\n","          big_cell_anchors    = torch.tensor(anchors['big'][ big_cell[0]*13 + big_cell[1]])\n","\n","          anchors_in_cell     = torch.cat((small_cell_anchors,\n","                                         medium_cell_anchors,\n","                                         big_cell_anchors))\n","\n","          pos_anchor, anchor_cell_location, cell_location, ignore_anchors = anchors_assignment(current_box,\n","                                                                         anchors_in_cell,\n","                                                                         grid_cells,\n","                                                                         used_anchor_cell,\n","                                                                         used_cell, idx)\n","\n","\n","          if pos_anchor is not None and pos_anchor < 3:\n","            pred_s_to_loss[grid_cells[0][0], grid_cells[0][1], pos_anchor, 4] = 0\n","            pred_offset = pred_s[grid_cells[0][0], grid_cells[0][1], pos_anchor]\n","          elif pos_anchor is not None and pos_anchor >= 3 and pos_anchor < 6:\n","            pred_m_to_loss[grid_cells[1][0], grid_cells[1][1], pos_anchor - 3, 4 ] = 0\n","            pred_offset = pred_m[grid_cells[1][0], grid_cells[1][1], pos_anchor - 3]\n","          elif pos_anchor is not None and pos_anchor>=6 and pos_anchor<9:\n","            pred_b_to_loss[grid_cells[2][0], grid_cells[2][1], pos_anchor - 6, 4] = 0\n","            pred_offset = pred_b[grid_cells[2][0], grid_cells[2][1], pos_anchor - 6]\n","\n","          for ignore_idx in ignore_anchors:\n","            if ignore_idx < 3:\n","              if pred_s_to_loss[grid_cells[0][0], grid_cells[0][1], ignore_idx, 4] == 1:\n","                pred_s_to_loss[grid_cells[0][0], grid_cells[0][1], ignore_idx, 4] = -1\n","            if ignore_idx >= 3 and ignore_idx<6:\n","              if pred_m_to_loss[grid_cells[1][0], grid_cells[1][1], ignore_idx - 3, 4] == 1:\n","                pred_m_to_loss[grid_cells[1][0], grid_cells[1][1], ignore_idx - 3, 4] = -1\n","            if ignore_idx >=6:\n","              if pred_b_to_loss[grid_cells[2][0], grid_cells[2][1], ignore_idx - 6, 4] == 1:\n","                pred_b_to_loss[grid_cells[2][0], grid_cells[2][1], ignore_idx - 6, 4] = -1\n","\n","\n","          used_cell.append(cell_location)\n","          used_anchor_cell.append(anchor_cell_location)\n","          if pos_anchor is not None:\n","            scale = 8 if anchor_cell_location[1]<3 else 16 if anchor_cell_location[1]<6 else 32\n","            assigned_anchor = anchors_in_cell[pos_anchor].unsqueeze(0)\n","\n","            pred_offsets.append(pred_offset)\n","            '''\n","            for d, b in zip(assigned_anchor, current_box):\n","              x1 = int(d[0])\n","              y1 = int(d[1])\n","              x2 = int(d[2])\n","              y2 = int(d[3])\n","              xx = int(b[0] - b[2]/2)\n","              yy = int(b[1] - b[3]/2)\n","              xx1 = int(b[2]/2 + b[0])\n","              yy1 = int(b[3]/2 + b[1])\n","              cv2.rectangle(img, (x1, y1), (x2, y2), (0,0,255), 2)\n","              cv2.rectangle(img, (xx,yy), (xx1, yy1), (0,255,0), 2)\n","            '''\n","            target_offset = target_calculation(assigned_anchor, current_box, scale)\n","            target_offsets.append(target_offset)\n","\n","      #plt.imshow(img)\n","      noobj_scores = torch.cat( (pred_s[pred_s_to_loss==1], pred_m[pred_m_to_loss==1], pred_b[pred_b_to_loss==1] ))\n","      noobj_loss = F.mse_loss(nn.functional.sigmoid(noobj_scores.to('cuda')),\n","                                                      torch.zeros_like(noobj_scores, device='cuda'), reduction='sum')/noobj_scores.numel()\n","      noobj_batch_loss += noobj_loss\n","      if pred_offsets:\n","        pred_offsets = torch.stack(pred_offsets)\n","\n","        obj_loss = F.mse_loss(nn.functional.sigmoid(pred_offsets[:,4]),\n","                                                      torch.ones_like(pred_offsets[:,4], device=pred_offsets.device), reduction='sum')/pred_offsets[:,4].numel()\n","        obj_batch_loss += obj_loss\n","\n","        target_offsets = torch.stack(target_offsets)\n","        xy_loss = F.mse_loss(nn.functional.sigmoid(pred_offsets[:,:2]), target_offsets[:,:2], reduction='sum')\n","        wh_loss = F.mse_loss(torch.exp(pred_offsets[:,2:4]), target_offsets[:,2:4], reduction='sum')\n","        offset_loss = (xy_loss + wh_loss)/target_offsets.numel()\n","        offsets_batch_loss += offset_loss\n","\n","  return {'offset_loss':offsets_batch_loss/16, 'obj_loss':obj_batch_loss/16 , 'noobj_loss':noobj_batch_loss/16}\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WMgkOvaMekiC"},"outputs":[],"source":["def calc_iou(box, anchors):\n","  anchors_area = ( anchors[:,2] - anchors[:,0] ) * ( anchors[:,3] - anchors[:,1] )\n","  boxes_area   = box[:,2] * box[:,3]\n","  upper_left_intersection = torch.max(anchors[:,:2].unsqueeze(1), (box[:,:2] - box[:,2:]/2))\n","  lower_right_intersection = torch.min(anchors[:,2:].unsqueeze(1), (box[:,:2] + box[:,2:]/2))\n","  intersection_dimension = (lower_right_intersection - upper_left_intersection).clamp(min=0)\n","  intersection_area = intersection_dimension[:,:,0] * intersection_dimension[:,:,1]\n","  union_area = anchors_area.unsqueeze(1) + boxes_area - intersection_area\n","  return intersection_area/union_area\n","\n","def anchors_assignment(box, anchors, cells_location, used_anchor_location_cell, used_cell, idx):\n","    neg_anchors = [0,1,2,3,4,5,6,7,8]\n","    pos_anchor = None\n","    triger = False\n","    discarded_anchors = []\n","    ignore_anchors = []\n","    confidence_supposed_pos = None\n","    cell_location = None\n","    ious = calc_iou(box, anchors)\n","    ious = torch.transpose(ious, 0, 1)\n","\n","    values, indices = torch.sort( ious, descending=True)\n","    values, indices = values[0], indices[0]\n","    greater_than_half = torch.where(values >= 0.1)[0]\n","    ignore_anchors = indices[greater_than_half]\n","    for num in range(len(indices)):\n","      if values[num] > 0.3:\n","        pos_anchor = indices[num]\n","        cell_index = int(pos_anchor/3)\n","        anchor_location_in_cell = [cells_location[cell_index], pos_anchor ]\n","        cell_location = cells_location[cell_index]\n","        if anchor_location_in_cell in used_anchor_location_cell:\n","          continue\n","        else:\n","          break\n","      else:\n","        return None, None, None, ignore_anchors\n","\n","    return pos_anchor, anchor_location_in_cell, cell_location, ignore_anchors\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ku_w5Kbz61EF"},"outputs":[],"source":["def target_calculation(assigned_anchors, assigned_bbox, scale):\n","\n","    for anchor, box in zip(assigned_anchors, assigned_bbox):\n","        x = (box[0] - ( int(box[0]/scale) * scale))/scale\n","        y = (box[1] - ( int(box[1]/scale) * scale))/scale\n","\n","        anchor_w = anchor[2] - anchor[0]\n","        anchor_h = anchor[3] - anchor[1]\n","\n","        w = box[2]/anchor_w\n","        h = box[3]/anchor_h\n","\n","        target = torch.tensor([x, y, w, h], dtype=torch.float32).to('cuda')\n","\n","\n","    return target\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29240,"status":"ok","timestamp":1692720272008,"user":{"displayName":"Hemo Hamo","userId":"14653600239742849398"},"user_tz":-120},"id":"rGhoaf7hmVGO","outputId":"3f51c615-b118-4695-b91a-0c172456b7e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":791,"status":"ok","timestamp":1692720272785,"user":{"displayName":"Hemo Hamo","userId":"14653600239742849398"},"user_tz":-120},"id":"KislBHadkeyj","outputId":"7a53d66e-7824-498c-cafe-23f82c865712"},"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/gdrive/MyDrive/wider_face_split.zip\n","   creating: wider_face_split/\n","  inflating: wider_face_split/readme.txt  \n","  inflating: wider_face_split/wider_face_test.mat  \n","  inflating: wider_face_split/wider_face_test_filelist.txt  \n","  inflating: wider_face_split/wider_face_train.mat  \n","  inflating: wider_face_split/wider_face_train_bbx_gt.txt  \n","  inflating: wider_face_split/wider_face_val.mat  \n","  inflating: wider_face_split/wider_face_val_bbx_gt.txt  \n"]}],"source":["!unzip /content/gdrive/MyDrive/wider_face_split.zip\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZ3nU_tskfLi"},"outputs":[],"source":["\n","!unzip /content/gdrive/MyDrive/WIDER_train.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RH2poGyxrcnF"},"outputs":[],"source":["\n","from PIL import Image\n","import torchvision\n","import numpy as np\n","import cv2\n","import torch\n","\n","class LoadDataSet(torch.utils.data.Dataset):\n","  def __init__(self, annotation_path, images_path, transforms):\n","    self.images_path_list = images_path\n","    self.annotation_path_list = annotation_path\n","    self.transform = transforms\n","    self.size = len(self.images_path_list)\n","    print(self.size)\n","\n","  def __getitem__(self, idx):\n","    Transform = torchvision.transforms.Normalize(mean=[0.485,0.456,0.406],\n","                                                 std=[0.229,0.224,0.225])\n","\n","    img_path = '/content/WIDER_train/images/'+self.images_path_list[idx]\n","    gt_boxes = self.annotation_path_list[idx]\n","    img = Image.open(img_path)\n","    img = np.asarray(img)\n","    img_size = img.shape\n","    image = cv2.resize(img/255., (416,416), interpolation=cv2.INTER_AREA)\n","    image = torch.as_tensor(image, dtype=torch.float32).permute(2,0,1)\n","    image = Transform(image)\n","    scalar = torch.tensor([1, 416/img_size[1], 416/img_size[0], 416/img_size[1], 416/img_size[0]], dtype=torch.float32)\n","\n","    boxes = []\n","    scale_small = 8\n","    scale_medium = 16\n","    scale_big = 32\n","\n","\n","    for box in gt_boxes:\n","        s_box = torch.tensor(box, dtype=torch.float32)*scalar\n","\n","        x_ctr = (s_box[3] + s_box[1])/2\n","        w     = (s_box[3] - s_box[1])\n","        #print(\"x_ctr\", x_ctr)\n","        x0_small_cell = int(x_ctr/scale_small)\n","        x0_medium_cell = int(x_ctr/scale_medium)\n","        x0_big_cell = int(x_ctr/scale_big)\n","\n","\n","        y_ctr = (s_box[4] + s_box[2])/2\n","        h     = (s_box[4] - s_box[2])\n","        #print(\"y_ctr\", y_ctr)\n","        y0_small_cell = int(y_ctr/scale_small)\n","        y0_medium_cell = int(y_ctr/scale_medium)\n","        y0_big_cell = int(y_ctr/scale_big)\n","\n","\n","        s_box[1] = x_ctr\n","        s_box[2] = y_ctr\n","        s_box[3] = w\n","        s_box[4] = h\n","\n","        boxes.append([1, [(x0_small_cell, y0_small_cell),(x0_medium_cell, y0_medium_cell), (x0_big_cell, y0_big_cell)], s_box[1:]])\n","\n","    return image, boxes, img_path\n","\n","  def __len__(self):\n","    return self.size\n","\n","def collate_fn(batch):\n","  images = []\n","  boxes = []\n","  for data in batch:\n","    images.append(data[0])\n","    boxes.append(data[1])\n","  return torch.stack(images, dim=0), boxes, data[2]\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uASR-uX0k-FT"},"outputs":[],"source":["file = open('/content/wider_face_split/wider_face_train_bbx_gt.txt')\n","lista=[]\n","inside_list=[]\n","names=[]\n","# this parameter is used to generate the anchors\n","all_boxes = []\n","triger=0\n","\n","for idx, line in enumerate(file.readlines()):\n","    if line[-4:]==\"jpg\\n\":\n","       names.append(line[:-1])\n","       if (inside_list==[] or triger==1) and idx!=0:\n","          names.pop(len(names)-2)\n","          inside_list = []\n","          triger = 0\n","          continue\n","       if idx!=0 and inside_list!=[]:\n","          lista.append(inside_list)\n","          inside_list = []\n","    if line[-4:]!='jpg\\n' and len(line)>15:\n","       num_list = line.strip()\n","       num_str = num_list.split()\n","       x1 = int(num_str[0])\n","       y1 = int(num_str[1])\n","       x2 = int(num_str[0]) + int(num_str[2])\n","       y2 = int(num_str[1]) + int(num_str[3])\n","       if num_str[2]!='0' and num_str[3]!='0' and num_str[7]!='1' and (x2-x1)>20 and (x2-x1)<1200 and (y2-y1)>20 and (y2-y1)<1200:\n","          array_int = [1, x1, y1, x2, y2]\n","          all_boxes.append(array_int[1:])\n","          inside_list.append(array_int)\n","       else:\n","          triger=1\n","    if idx == 185183:\n","       if inside_list!=[] and triger==0:\n","          lista.append(inside_list)\n","       elif inside_list==[] and triger==1:\n","          names.pop()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":195,"status":"ok","timestamp":1692720320101,"user":{"displayName":"Hemo Hamo","userId":"14653600239742849398"},"user_tz":-120},"id":"arF69zm-k-a3","outputId":"1f1c97cc-7438-4ab4-d5e3-e766cd01e32a"},"outputs":[{"output_type":"stream","name":"stdout","text":["9074\n"]}],"source":["#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","dataset = LoadDataSet(annotation_path=lista, images_path=names, transforms=None)\n","data_loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=collate_fn, drop_last=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8gqOs24Ysu0X"},"outputs":[],"source":["import torch\n","import numpy as np\n","new_centroids = torch.tensor([[  0.0000,   0.0000,  13.2136,  21.0693],\n","        [  0.0000,   0.0000,  18.2718,  33.5538],\n","        [  0.0000,   0.0000,  28.8336,  45.1136],\n","        [  0.0000,   0.0000,  36.9599,  76.1135],\n","        [  0.0000,   0.0000,  55.4889,  52.9748],\n","        [  0.0000,   0.0000,  57.9636, 119.5746],\n","        [  0.0000,   0.0000,  96.7757,  97.8682],\n","        [  0.0000,   0.0000, 118.6441, 183.7684],\n","        [  0.0000,   0.0000, 199.0680, 252.7008]], dtype=torch.float32)"]},{"cell_type":"code","source":[],"metadata":{"id":"OFuyKOuvv3nc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PMk2_dlesvTz"},"outputs":[],"source":["\n","\n","anchors_small = []\n","anchors_medium = []\n","anchors_big = []\n","\n","for i in range(52):\n","  for j in range(52):\n","    anchors_per_cell_small = []\n","    anchors_per_cell_medium = []\n","    anchors_per_cell_big = []\n","    for k, box in enumerate(new_centroids[:3]):\n","        if i<52 and j<52:\n","          anchor = [ (i)*8 + 4 - int((box[2] - box[0])/2), (j)*8 + 4 - int((box[3] - box[1])/2),\n","                    (i)*8 + 4 + int((box[2] - box[0])/2), (j)*8 + 4 + int((box[3] - box[1])/2)]\n","          if sum(torch.tensor(anchor) >= 0)==4:\n","            anchors_per_cell_small.append(anchor)\n","          else:\n","            anchors_per_cell_small.append([0.0, 0.0, 0.0, 0.0])\n","\n","    for k, box in enumerate(new_centroids[3:6]):\n","      if i<26 and j<26:\n","        anchor = [ (i)*16 + 8 - int((box[2] - box[0])/2), (j)*16 + 8 - int((box[3] - box[1])/2),\n","                  (i)*16 + 8 + int((box[2] - box[0])/2), (j)*16 + 8 + int((box[3] - box[1])/2)]\n","        if sum(torch.tensor(anchor) >= 0)==4:\n","          anchors_per_cell_medium.append(anchor)\n","        else:\n","          anchors_per_cell_medium.append([0.0, 0.0, 0.0, 0.0])\n","\n","\n","    for k, box in enumerate(new_centroids[6:]):\n","        if i<13 and j<13:\n","          anchor = [ (i)*32 + 16 - int((box[2]- box[0])/2), (j)*32 + 16 - int((box[3] - box[1])/2),\n","                    (i)*32+16 + int((box[2]- box[0])/2), (j)*32 + 16 + int((box[3] - box[1])/2)]\n","          if sum(torch.tensor(anchor) >= 0)==4:\n","            anchors_per_cell_big.append(anchor)\n","          else:\n","            anchors_per_cell_big.append([0.0, 0.0, 0.0, 0.0])\n","\n","\n","    if i<52 and j<52:\n","          anchors_small.append(anchors_per_cell_small)\n","\n","    if i<26 and j<26:\n","        anchors_medium.append(anchors_per_cell_medium)\n","\n","    if i<13 and j<13:\n","        anchors_big.append(anchors_per_cell_big)\n","\n","all_anchors = {'small':anchors_small, 'medium':anchors_medium, 'big':anchors_big}\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"zNa1JDzxv3wK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9L2YBhF5v38t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"c9OcTF5Fv4CF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OADrQ0o4v4E0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SSd8rYfWv4IN"},"execution_count":null,"outputs":[]}]}